{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.4"
    },
    "colab": {
      "name": "Codenames.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/banksean/wordgames/blob/master/Codenames.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bq1LnYaLZSk6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gensim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkOVNiIqZrGN",
        "colab_type": "code",
        "outputId": "d32fa051-9672-4e2e-a15d-766e29dbd6e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        }
      },
      "source": [
        "!wget -P /root/input/ -c \"https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\""
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-03-19 01:17:07--  https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.217.10.118\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.217.10.118|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1647046227 (1.5G) [application/x-gzip]\n",
            "Saving to: ‘/root/input/GoogleNews-vectors-negative300.bin.gz’\n",
            "\n",
            "GoogleNews-vectors- 100%[===================>]   1.53G  17.0MB/s    in 97s     \n",
            "\n",
            "2020-03-19 01:18:45 (16.2 MB/s) - ‘/root/input/GoogleNews-vectors-negative300.bin.gz’ saved [1647046227/1647046227]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3dXoV83cM4a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!wget -P /root/input/ -c \"http://nlp.stanford.edu/data/wordvecs/glove.twitter.27B.zip\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISS_jyVKZ6wT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EMBEDDING_FILE = '/root/input/GoogleNews-vectors-negative300.bin.gz'\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PHuwOJUUZSk-",
        "colab_type": "code",
        "outputId": "c40e5799-cd4d-412a-8062-8577d6d7d4b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "source": [
        "\n",
        "model = gensim.models.KeyedVectors.load_word2vec_format(EMBEDDING_FILE, binary=True, limit=500000)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3TH6nSxKgDi5",
        "colab_type": "code",
        "outputId": "e5c4cd82-b168-44a8-c65d-08003d08837f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        }
      },
      "source": [
        "# Some other pre-trained vectors from Stanford NLP:  https://github.com/stanfordnlp/GloVe\n",
        "\n",
        "# Twitter vectors (contains lots of non-EN strings)\n",
        "#!wget -P /root/input/ -c \"http://nlp.stanford.edu/data/wordvecs/glove.twitter.27B.zip\"\n",
        "#!unzip /root/input/glove.twitter.27B.zip -d /root/input/\n",
        "\n",
        "# Wikipedia:\n",
        "!wget -P /root/input/ -c  \"http://nlp.stanford.edu/data/wordvecs/glove.6B.zip\"\n",
        "!unzip /root/input/glove.6B.zip -d /root/input/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-03-14 00:59:04--  http://nlp.stanford.edu/data/wordvecs/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/wordvecs/glove.6B.zip [following]\n",
            "--2020-03-14 00:59:04--  https://nlp.stanford.edu/data/wordvecs/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/wordvecs/glove.6B.zip [following]\n",
            "--2020-03-14 00:59:05--  http://downloads.cs.stanford.edu/nlp/data/wordvecs/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182753 (822M) [application/zip]\n",
            "Saving to: ‘/root/input/glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  2.03MB/s    in 6m 28s  \n",
            "\n",
            "2020-03-14 01:05:33 (2.12 MB/s) - ‘/root/input/glove.6B.zip’ saved [862182753/862182753]\n",
            "\n",
            "Archive:  /root/input/glove.6B.zip\n",
            "  inflating: /root/input/glove.6B.100d.txt  \n",
            "  inflating: /root/input/glove.6B.200d.txt  \n",
            "  inflating: /root/input/glove.6B.300d.txt  \n",
            "  inflating: /root/input/glove.6B.50d.txt  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VFIZdF-Rcm-9",
        "colab_type": "code",
        "outputId": "99dddff6-5e0e-4a47-8986-315af9f53d7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "source": [
        "from gensim.test.utils import datapath, get_tmpfile\n",
        "from gensim.scripts.glove2word2vec import glove2word2vec\n",
        "#glove_file = datapath('/root/input/glove.twitter.27B.25d.txt')\n",
        "glove_file = datapath('/root/input/glove.6B.300d.txt')\n",
        "tmp_file = get_tmpfile(\"test_word2vec.txt\")\n",
        "_ = glove2word2vec(glove_file, tmp_file)\n",
        "\n",
        "model_2 = gensim.models.KeyedVectors.load_word2vec_format(tmp_file, limit=500000)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJqzJu19ZSlC",
        "colab_type": "text"
      },
      "source": [
        "We limit the vocabulary to the 500,000 most common words.  Even at 500,000, it starts to get to nonsense words.  Here are the top 50 and bottom 50 words by frequency. And even for the real words that are infrequent, if a word is too obscure, it wouldn't make for a good clue."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EYlNmkn1ZSlD",
        "colab_type": "code",
        "outputId": "5a4b640d-cde5-4856-a1b7-81c96d27fcdd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "source": [
        "print(\"Most common:\",model.index2word[:50])\n",
        "print(\"Least common:\",model.index2word[-50:])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Most common: ['</s>', 'in', 'for', 'that', 'is', 'on', '##', 'The', 'with', 'said', 'was', 'the', 'at', 'not', 'as', 'it', 'be', 'from', 'by', 'are', 'I', 'have', 'he', 'will', 'has', '####', 'his', 'an', 'this', 'or', 'their', 'who', 'they', 'but', '$', 'had', 'year', 'were', 'we', 'more', '###', 'up', 'been', 'you', 'its', 'one', 'about', 'would', 'which', 'out']\n",
            "Least common: ['ideological_affinity', 'Rashtriya_Rifles_RR', 'Pedrotti', 'Frysinger', 'Ralph_Sacco', 'Ryan_Nece', 'Homs_Syria', 'BACK_TO_BACK', 'Nag_Hammadi', 'Dashan', 'Murape', 'Majolica', 'Sundvold', 'Jerryd', 'administered_subcutaneously', 'Pierre_Luc_Gagnon', 'Fedrizzi', 'CD_ROMS', 'Raynham_Mass.', 'NN_Vohra', 'Barraba', 'Delta_Upsilon', 'Roilo_Golez', 'Cindy_Scroggins', 'Iter', 'Ford_Expeditions', 'La_Toussuire', 'Hooksett_NH', 'ITCTransmission', 'wakeskate', 'Fervor', 'SAFT', 'steam_boiler', 'Moskwa', 'Inet_electronic', '2A_1A', 'pituitary_tumor', 'Westernbank', '3DV', 'Supremely', 'Mellars', 'JUDGMENT', 'thinnest_smartphone', 'BY_ROD_KLOECKNER', 'gamepads', 'Reventon', 'LongJump', 'Whitby_Dunlops', 'Chasing_Value', 'Pollution_Control_Agency']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dSX93wZCZSlG",
        "colab_type": "text"
      },
      "source": [
        "Here's an example Codenames board.  `blue` is one team's words, `red` the other and `assassin` is the assassin word."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Xw5IZdSZSlH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "board = {\n",
        "    'blue': ['ambulance', 'hospital', 'spell', 'lock', 'charge', 'tail', 'link', 'cook', 'web'],\n",
        "    'red': ['cat', 'button', 'pipe', 'pants', 'mount', 'sleep', 'stick', 'file', 'worm'],\n",
        "    'assassin': 'doctor'\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LEyE0_o_ZSlK",
        "colab_type": "text"
      },
      "source": [
        "We can use gensim to find the 10 words most related to \"ambulance\" in this word2vec model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xhmzm15ZSlL",
        "colab_type": "code",
        "outputId": "6fae25fc-ee86-40ef-c276-fc2824272bce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        }
      },
      "source": [
        "model.similar_by_word('ambulance', topn=10)"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('paramedics', 0.7590752243995667),\n",
              " ('ambulances', 0.7493596076965332),\n",
              " ('Ambulance', 0.7236292362213135),\n",
              " ('paramedic', 0.6621334552764893),\n",
              " ('Ambulance_paramedics', 0.6315338611602783),\n",
              " ('Ambulances', 0.6211477518081665),\n",
              " ('LifeFlight_helicopter', 0.6147335171699524),\n",
              " ('hospital', 0.6099206209182739),\n",
              " ('Paramedics', 0.6081751585006714),\n",
              " ('Ambulance_Service', 0.6080098152160645)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LTdQwps0ZSlO",
        "colab_type": "text"
      },
      "source": [
        "Each line is the word, followed by how similar the word is to \"ambulance.\" Some of these words word be useful, \"parametics\" for instance, but many are just other forms of the word \"ambulance.\"\n",
        "\n",
        "gensim allows us to directly find words the most similar to a whole group of words at one time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6JXVjtL0ZSlP",
        "colab_type": "code",
        "outputId": "dd171ee5-cb76-41ce-aa99-ef63688e6abf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        }
      },
      "source": [
        "model.most_similar(positive=board['blue'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('them', 0.5683777928352356),\n",
              " ('immediately', 0.5638923048973083),\n",
              " ('put', 0.5584514737129211),\n",
              " ('one', 0.5529150366783142),\n",
              " ('another', 0.5521906614303589),\n",
              " ('but', 0.551121175289154),\n",
              " ('can', 0.5502618551254272),\n",
              " ('not', 0.5444289445877075),\n",
              " ('without', 0.542267382144928),\n",
              " ('could', 0.5401044487953186)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ScvEhPWxZSlS",
        "colab_type": "text"
      },
      "source": [
        "As we can see, it produces a lot of nonsense words. We can use `restrict_vocab` to limit results to only the top n most common words in the corpus."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CTMk1QZiZSlT",
        "colab_type": "code",
        "outputId": "aaad355d-018d-43b2-d0d2-826078341b87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        }
      },
      "source": [
        "model.most_similar(\n",
        "    positive=board['blue'],\n",
        "    restrict_vocab=5000,\n",
        "    topn=20\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('them', 0.5683777928352356),\n",
              " ('immediately', 0.5638923048973083),\n",
              " ('put', 0.5584514737129211),\n",
              " ('one', 0.5529150366783142),\n",
              " ('another', 0.5521906614303589),\n",
              " ('but', 0.551121175289154),\n",
              " ('can', 0.5502618551254272),\n",
              " ('not', 0.5444289445877075),\n",
              " ('without', 0.542267382144928),\n",
              " ('could', 0.5401044487953186),\n",
              " ('instead', 0.5379015803337097),\n",
              " ('so', 0.5321692824363708),\n",
              " ('side', 0.5316520929336548),\n",
              " ('then', 0.5312769412994385),\n",
              " ('turn', 0.529608964920044),\n",
              " ('back', 0.5288029313087463),\n",
              " ('that', 0.525951087474823),\n",
              " ('up', 0.5257615447044373),\n",
              " ('.', 0.5256825089454651),\n",
              " ('which', 0.5238362550735474)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1sbTtsWAZSlW",
        "colab_type": "text"
      },
      "source": [
        "This looks much better, and produces some decent clues.  \n",
        "* \"bed\", \"paramedics\", \"emergency\" all relate to \"ambulance\" and \"hospital.\" \n",
        "* \"jail\" could relate to \"lock\" and \"charge.\" \n",
        "* \"click\" to \"web\" and \"link.\"\n",
        "\n",
        "But “bed” would also relate to the other team’s word “sleep”; and “click” with “button.” It would be bad to give clues which could point to the opponent’s cards. \n",
        "\n",
        "gensim allows for negative examples to be included as well to help avoid that."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UIzZz8DZZSlX",
        "colab_type": "code",
        "outputId": "27fb2acb-aeb7-41be-d386-fbfa13b898a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        }
      },
      "source": [
        "model.most_similar(\n",
        "    positive=board['blue'],\n",
        "    negative=board['red'],\n",
        "    restrict_vocab=50000\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('services', 0.3988395929336548),\n",
              " ('serving', 0.3247905969619751),\n",
              " ('hospitals', 0.31964364647865295),\n",
              " ('providing', 0.3174983263015747),\n",
              " ('service', 0.31196415424346924),\n",
              " ('surrey', 0.3039936423301697),\n",
              " ('provided', 0.30171409249305725),\n",
              " ('midlands', 0.2996490001678467),\n",
              " ('liaison', 0.2964310050010681),\n",
              " ('england', 0.29458382725715637)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x5rDXzCDZSlZ",
        "colab_type": "text"
      },
      "source": [
        "I really like the clue \"telemedicine.\" It's non-obvious, but relates to four words: \"web,\" \"link,\" \"ambulance\" and \"hospital.\" This shows the potential for this method to produce novel clues.\n",
        "\n",
        "Let's say that the clue were \"telemedicine\" and the four words were removed from the board, then the next team got a turn.  What might their clues be?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eR-fonvkZSla",
        "colab_type": "code",
        "outputId": "1304c11b-7f03-4ef3-c217-b0e89d857405",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        }
      },
      "source": [
        "board = {\n",
        "    'blue': ['spell', 'lock', 'charge', 'tail', 'link'],\n",
        "#    'red': ['cat', 'button', 'pipe', 'pants', 'mount', 'sleep', 'stick', 'file', 'worm'],\n",
        "    'red': ['cat', 'button', 'pipe', 'pants', 'mount', 'sleep', 'stick', 'file', 'worm'],\n",
        "    'assassin': 'doctor'\n",
        "}\n",
        "\n",
        "model.most_similar(\n",
        "    positive=board['red'],\n",
        "    negative=board['blue'],\n",
        "    restrict_vocab=50000\n",
        ")"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('pillow', 0.43686944246292114),\n",
              " ('bra', 0.3842337727546692),\n",
              " ('couch', 0.38342970609664917),\n",
              " ('tub', 0.37922775745391846),\n",
              " ('closet', 0.36959999799728394),\n",
              " ('sofa', 0.36713898181915283),\n",
              " ('bathroom', 0.3662588596343994),\n",
              " ('bed', 0.36348700523376465),\n",
              " ('crotch', 0.36245280504226685),\n",
              " ('spoon', 0.36179912090301514)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FTsE-IdUZSlc",
        "colab_type": "text"
      },
      "source": [
        "This appears much less successful.  The top words mostly just seem to relate to a singe word:\n",
        "* pillow -> sleep\n",
        "* bra -> pants\n",
        "* couch -> sleep? cat?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UYOz06KLZSld",
        "colab_type": "code",
        "outputId": "88c7f1e3-ade8-44d3-889d-85f19164a0e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        }
      },
      "source": [
        "king = model_2.get_vector(\"king\")\n",
        "man = model_2.get_vector(\"male\")\n",
        "woman = model_2.get_vector(\"female\")\n",
        "\n",
        "model_2.similar_by_vector(king + woman - man)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('king', 0.9058233499526978),\n",
              " ('queen', 0.6294318437576294),\n",
              " ('prince', 0.5422012805938721),\n",
              " ('kingdom', 0.5360386371612549),\n",
              " ('monarch', 0.520081639289856),\n",
              " ('ii', 0.48105159401893616),\n",
              " ('throne', 0.48008933663368225),\n",
              " ('crown', 0.4702116847038269),\n",
              " ('reign', 0.46325474977493286),\n",
              " ('iii', 0.4566229581832886)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lINrFtC0R4IE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from itertools import chain, combinations\n",
        "\n",
        "def powerset(iterable):\n",
        "    s = list(iterable)\n",
        "    return chain.from_iterable(combinations(s, r) for r in range(len(s)+1))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ay_I_KRzh5II",
        "colab_type": "code",
        "outputId": "9b77600e-bc68-4d75-c6e4-bace3e6a9faa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        }
      },
      "source": [
        "!wget -P /root/input -c \"https://raw.githubusercontent.com/seanlyons/codenames/master/wordlist.txt\""
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-03-19 01:23:23--  https://raw.githubusercontent.com/seanlyons/codenames/master/wordlist.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1143 (1.1K) [text/plain]\n",
            "Saving to: ‘/root/input/wordlist.txt’\n",
            "\n",
            "\rwordlist.txt          0%[                    ]       0  --.-KB/s               \rwordlist.txt        100%[===================>]   1.12K  --.-KB/s    in 0s      \n",
            "\n",
            "2020-03-19 01:23:23 (247 MB/s) - ‘/root/input/wordlist.txt’ saved [1143/1143]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-hF3TCVicyN",
        "colab_type": "code",
        "outputId": "7606c220-3a64-466f-bc21-05c9ca48b735",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "# Using readlines() \n",
        "wordsfile = open('/root/input/wordlist.txt', 'r') \n",
        "words = wordsfile.readlines()\n",
        "words = list(map(lambda x: x.strip(), words))\n",
        "\n",
        "import random\n",
        "\n",
        "def new_board(words, first_team=\"blue\"):\n",
        "  bag = list(words)\n",
        "  random.shuffle(bag)\n",
        "\n",
        "  idx = 8 if first_team is \"blue\" else 9\n",
        "  red = bag[:idx]\n",
        "  bag = bag[idx:]\n",
        "  \n",
        "  idx = 8 if first_team is \"red\" else 9\n",
        "  blue = bag[:idx]\n",
        "  bag = bag[idx:]\n",
        "  \n",
        "  bystanders = bag[:7]\n",
        "  bag = bag[7:]\n",
        "\n",
        "  assassin = bag[0]\n",
        "\n",
        "  board = {\n",
        "      'red': red,\n",
        "      'blue': blue,\n",
        "      'bystanders': bystanders,\n",
        "      'assassin': assassin\n",
        "  }\n",
        "  return board\n",
        "\n",
        "board = new_board(words)\n",
        "print(board)\n",
        "\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'red': ['cricket', 'fork', 'bow', 'snowman', 'iron', 'mass', 'flute', 'water'], 'blue': ['hotel', 'worm', 'stick', 'spike', 'lap', 'bank', 'model', 'ghost', 'berlin'], 'bystanders': ['night', 'sub', 'war', 'rock', 'giant', 'robot', 'ivory'], 'assassin': 'alien'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ufHhOVkSZppo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "outputId": "7ddc551d-b68c-4cab-dd79-10f4a87d643e"
      },
      "source": [
        "RESTRICT_VOCAB=5000\n",
        "SCORE_THRESHOLD=0.0 #1936\n",
        "\n",
        "def word2vec_guess(model, clue, n, terms):\n",
        "  ret = set()\n",
        "  terms = set([term for term in terms if term in model.vocab])\n",
        "  for i in range(n):\n",
        "    g = model.most_similar_to_given(clue, list(terms))\n",
        "    ret.add(g)\n",
        "    terms.discard(g)\n",
        "  return ret\n",
        "\n",
        "# Make sure to add the asassin to negative (the other team's terms) before calling this.\n",
        "def word2vec_hints(model, board, player='blue'):\n",
        "  opponent = 'red' if player is 'blue' else 'red'\n",
        "  positive = set([w for w in board[player] if w in model.vocab])\n",
        "  negative = set([w for w in board[opponent] if w in model.vocab])\n",
        "  if board['assassin'] in model.vocab:\n",
        "    negative.add(board['assassin'])\n",
        "\n",
        "  # TODO: Expand negative with N similar terms to each word in negative?\n",
        "  # This may already happen due to vector math in word2vec.\n",
        "\n",
        "  # Enumerate combinations of 1, 2, 3 terms\n",
        "  p = powerset(positive)\n",
        "  clues = []\n",
        "  for s in p:\n",
        "    if len(s) == 0:\n",
        "      continue\n",
        "    if len(s) > 3:\n",
        "      break\n",
        "    candidates = model.most_similar(\n",
        "      list(s),\n",
        "      list(negative),\n",
        "      topn=10,\n",
        "      restrict_vocab=RESTRICT_VOCAB\n",
        "    )\n",
        "    hi_score = 0.0\n",
        "    hi_clue = None\n",
        "\n",
        "    for term, score in candidates:\n",
        "      if term.lower() in positive | negative or term.startswith('afp'):\n",
        "        continue\n",
        "      if score > hi_score and score > SCORE_THRESHOLD:\n",
        "        hi_score = score\n",
        "        hi_clue = term\n",
        "\n",
        "    if hi_clue is not None:\n",
        "      clues.append({'targets': s, 'hint': hi_clue, 'score': hi_score})\n",
        "\n",
        "  # This ranking penalizes/benefits the higher-term-count clues.\n",
        "  # TODO: Tune this.\n",
        "  clues.sort(key=lambda x: x['score']*len(x['targets']), reverse=True)\n",
        "  return clues\n",
        "\n",
        "board = new_board(words)\n",
        "hint_list = word2vec_hints(model, board)\n",
        "all_words = set(board['red']) | set(board['blue']) | set([board['assassin']])\n",
        "#print(hint_list)\n",
        "print(len(hint_list), ' hints')\n",
        "\n",
        "score = 0\n",
        "total_possible = 0\n",
        "for n in range(len(hint_list)):\n",
        "  g = word2vec_guess(model, hint_list[n]['hint'], \n",
        "        len(hint_list[n]['targets']),\n",
        "        all_words # | set(board['assassin']) # Whole board\n",
        "        )\n",
        "  correct = set(board['blue']) & set(g)\n",
        "  incorrect = set(board['red']) & set(g)\n",
        "  total_possible += len(hint_list[n]['targets'])\n",
        "\n",
        "  # TODO: actual scoring. But for now:\n",
        "  # Ignore target words from the hints, just look at hint, n and what's on the board.\n",
        "  # If all n of the guesses are on your squares (regardless of target words) then\n",
        "  # that's n points.\n",
        "  score += len(correct) - len(incorrect)\n",
        "  \n",
        "  #print('  hint: ', hint_list[n])\n",
        "  #print('  guess: ', g)\n",
        "  #print('correct: ', correct)\n",
        "\n",
        "\n",
        "print('total score: ', score, ' ', (score/total_possible))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "129  hints\n",
            "total score:  312   0.9369369369369369\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2LHNrB82AnMU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Stuff to try next: \n",
        "# - DONE: Different pre-built model weights: https://github.com/3Top/word2vec-api#where-to-get-a-pretrained-models\n",
        "#   - Verdict: Google News still gives best results\n",
        "#   - Twitter model had too many non-english words\n",
        "# - DONE: Imporove guess/hint generation by enumerating combinations of words and sorting by scores\n",
        "# - Try building custom word2vec models on celebrity gossip, e.g.\n",
        "\n",
        "# Hint vocabulary: \n",
        "# https://colab.research.google.com/github/henrywoo/MyML/blob/master/Copy_of_nlu_1.ipynb\n",
        "# - start with codewords\n",
        "# - for each:\n",
        "#   - use wordnet to branch out to related words\n",
        "#   - store each, along with its relation type (rhymes, opposites, synonyms, homopones, etc)\n",
        "# - for generating hints:\n",
        "#   - pick a relation type with some probability, weighted by bot's \"personality\" (a mix of relation types)\n",
        "\n",
        "# Emoji instead of codewords and hints\n",
        "# - Use top n emoji from emojipedia\n",
        "#   - For hints, but also for codewords?\n",
        "\n",
        "# DONE: Generate some random boards and try this out for real\n",
        "# Word list links\n",
        "# - https://raw.githubusercontent.com/seanlyons/codenames/master/wordlist.txt\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ga--684Iqge8",
        "colab_type": "code",
        "outputId": "3efad4dd-828f-4d86-db11-97ed509f4054",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "import nltk\n",
        "assert(nltk.download('wordnet'))  # Make sure we have the wordnet data.\n",
        "from nltk.corpus import wordnet as wn"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VTl_fZDKzfME",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BehaV0wsrIq2",
        "colab_type": "code",
        "outputId": "28a559ba-732e-4dd4-9490-fc397ae8d3f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import json\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "ps = PorterStemmer()\n",
        "\n",
        "hypo = lambda s: s.hyponyms()\n",
        "hyper = lambda s: s.hypernyms()\n",
        "\n",
        "def related_words(wn, word):\n",
        "  ret = set()\n",
        "  synonyms = []\n",
        "  antonyms = []\n",
        "\n",
        "  # More specific terms\n",
        "  hyponyms = []\n",
        "\n",
        "  # More broad terms\n",
        "  hypernyms = []\n",
        "\n",
        "  for s in wn.synsets(ps.stem(word)):\n",
        "    hyponyms.extend([s.lemmas()[0].name() for s in s.closure(hypo, depth=1)])\n",
        "    hypernyms.extend([s.lemmas()[0].name() for s in s.closure(hyper, depth=1)])\n",
        "\n",
        "    for l in s.lemmas():\n",
        "      synonyms.append(l.name())\n",
        "      for a in l.antonyms():\n",
        "        antonyms.append(a.name())\n",
        "\n",
        "  return {\n",
        "      'synonyms': list(set(synonyms)),\n",
        "      'antonyms': list(set(antonyms)),\n",
        "      'hyponyms': list(set(hyponyms)),\n",
        "      'hypernyms': list(set(hypernyms))\n",
        "  }\n",
        "\n",
        "print(json.dumps(related_words(wn, 'good'), indent=2))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"synonyms\": [\n",
            "    \"practiced\",\n",
            "    \"adept\",\n",
            "    \"skillful\",\n",
            "    \"sound\",\n",
            "    \"unspoilt\",\n",
            "    \"expert\",\n",
            "    \"beneficial\",\n",
            "    \"in_force\",\n",
            "    \"soundly\",\n",
            "    \"well\",\n",
            "    \"serious\",\n",
            "    \"ripe\",\n",
            "    \"good\",\n",
            "    \"secure\",\n",
            "    \"commodity\",\n",
            "    \"full\",\n",
            "    \"near\",\n",
            "    \"trade_good\",\n",
            "    \"just\",\n",
            "    \"effective\",\n",
            "    \"goodness\",\n",
            "    \"dear\",\n",
            "    \"undecomposed\",\n",
            "    \"salutary\",\n",
            "    \"dependable\",\n",
            "    \"proficient\",\n",
            "    \"upright\",\n",
            "    \"safe\",\n",
            "    \"thoroughly\",\n",
            "    \"respectable\",\n",
            "    \"estimable\",\n",
            "    \"right\",\n",
            "    \"honorable\",\n",
            "    \"in_effect\",\n",
            "    \"skilful\",\n",
            "    \"unspoiled\",\n",
            "    \"honest\"\n",
            "  ],\n",
            "  \"antonyms\": [\n",
            "    \"evil\",\n",
            "    \"badness\",\n",
            "    \"ill\",\n",
            "    \"evilness\",\n",
            "    \"bad\"\n",
            "  ],\n",
            "  \"hyponyms\": [\n",
            "    \"saintliness\",\n",
            "    \"beneficence\",\n",
            "    \"shopping\",\n",
            "    \"fungible\",\n",
            "    \"wisdom\",\n",
            "    \"virtue\",\n",
            "    \"drygoods\",\n",
            "    \"common_good\",\n",
            "    \"future\",\n",
            "    \"fancy_goods\",\n",
            "    \"worthiness\",\n",
            "    \"consumer_goods\",\n",
            "    \"basic\",\n",
            "    \"sporting_goods\",\n",
            "    \"benignity\",\n",
            "    \"summum_bonum\",\n",
            "    \"desirability\",\n",
            "    \"kindness\",\n",
            "    \"worldly_possession\",\n",
            "    \"middling\",\n",
            "    \"merchandise\",\n",
            "    \"benefit\",\n",
            "    \"better\",\n",
            "    \"import\",\n",
            "    \"salvage\",\n",
            "    \"export\",\n",
            "    \"optimum\",\n",
            "    \"entrant\"\n",
            "  ],\n",
            "  \"hypernyms\": [\n",
            "    \"advantage\",\n",
            "    \"morality\",\n",
            "    \"artifact\",\n",
            "    \"quality\"\n",
            "  ]\n",
            "}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ea5OfmCA2cWV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "143bee9d-1a10-4624-cbb7-712880e03ca9"
      },
      "source": [
        "\n",
        "def wordnet_hints(wn, board, player='blue'):\n",
        "  opponent = 'red' if player is 'blue' else 'red'\n",
        "\n",
        "  # neg_terms should contain all of the opponent's codewords\n",
        "  # plus all of those codewords' related words (so hints don't point to your\n",
        "  # opponent's codewords).\n",
        "  neg_terms = set()\n",
        "  for word in board[opponent]:\n",
        "    word = ps.stem(word)\n",
        "    rel_words = related_words(wn, word)\n",
        "    neg_terms.union(set(rel_words['synonyms']))\n",
        "    neg_terms.union(set(rel_words['antonyms']))\n",
        "    neg_terms.union(set(rel_words['hyponyms']))\n",
        "    neg_terms.union(set(rel_words['hypernyms']))\n",
        "\n",
        "  # iterate over 1-3 word permutations of board[player]\n",
        "  p = powerset(board[player])\n",
        "  hints = []\n",
        "\n",
        "  for s in p:\n",
        "    if len(s) == 0:\n",
        "      continue\n",
        "    if len(s) > 3:\n",
        "      break\n",
        "\n",
        "    pos_terms = []\n",
        "    for w in s:\n",
        "      w = ps.stem(w)\n",
        "      rel_words = related_words(wn, w)\n",
        "      all_related = set(rel_words['synonyms'])\n",
        "      all_related.union(set(rel_words['antonyms']))\n",
        "      all_related.union(set(rel_words['hyponyms']))\n",
        "      all_related.union(set(rel_words['hypernyms']))\n",
        "      pos_terms.append(all_related)\n",
        "\n",
        "    pos_terms = pos_terms[0].intersection(*pos_terms)\n",
        "\n",
        "    candidates = list(pos_terms.difference(neg_terms))\n",
        "    if len(candidates) is 0:\n",
        "      continue\n",
        "    \n",
        "    #print(s)\n",
        "    #print(\" candidate hints: \", candidates)\n",
        "    # print(\" conflicting hints: \", neg_terms.intersection(pos_terms))\n",
        "\n",
        "    for term in candidates:\n",
        "      if term.lower() in pos_terms | neg_terms | set(s) or term.lower() is board['assassin'] or '_' in term:\n",
        "        continue\n",
        "      hints.append({'targets': s, 'hint': term})\n",
        "\n",
        "  hints = sorted(hints, key=lambda x: len(x['targets']), reverse=True)\n",
        "  return hints\n",
        "\n",
        "def wordnet_guess(wn, clue, n, terms):\n",
        "  ret = set()\n",
        "  for i in range(n):\n",
        "    guesses = set()\n",
        "    #g = model.most_similar_to_given(clue, list(terms))\n",
        "    #ret.add(g)\n",
        "    #terms.discard(g)\n",
        "\n",
        "    rel_words = related_words(wn, clue)\n",
        "    #print('related words: ', json.dumps(rel_words, indent=2))\n",
        "    guesses = guesses.union(set(rel_words['synonyms']))\n",
        "    guesses = guesses.union(set(rel_words['antonyms']))\n",
        "    guesses = guesses.union(set(rel_words['hyponyms']))\n",
        "    guesses = guesses.union(set(rel_words['hypernyms']))\n",
        "\n",
        "    #print('guesses for ', clue, ': ', guesses)\n",
        "    guesses = guesses.intersection(terms)\n",
        "    #print('guesses filtered for ', clue, ': ', guesses)\n",
        "    if len(guesses) > 0:\n",
        "      g = list(guesses)[0]\n",
        "      ret.add(g)\n",
        "      terms.discard(g)\n",
        "\n",
        "  return ret\n",
        "\n",
        "def evaluate_wordnet(seed):\n",
        "  random.seed(seed)\n",
        "  board = new_board(words)\n",
        "  hint_list = wordnet_hints(wn, board, player='blue')\n",
        "\n",
        "  #red_hints = wordnet_hints(wn, board, player='red')\n",
        "\n",
        "  all_words = set(board['red']) | set(board['blue']) | set([board['assassin']])\n",
        "  #print(hint_list)\n",
        "  print(len(hint_list), ' hints')\n",
        "\n",
        "  score = 0\n",
        "  total_possible = 0\n",
        "  for n in range(len(hint_list)):\n",
        "    g = wordnet_guess(wn, hint_list[n]['hint'], \n",
        "          len(hint_list[n]['targets']),\n",
        "          all_words # | set(board['assassin']) # Whole board\n",
        "          )\n",
        "    correct = set(board['blue']) & set(g)†\n",
        "    incorrect = set(board['red']) & set(g)\n",
        "    total_possible += len(hint_list[n]['targets'])\n",
        "\n",
        "    # TODO: actual scoring. But for now:\n",
        "    # Ignore target words from the hints, just look at hint, n and what's on the board.\n",
        "    # If all n of the guesses are on your squares (regardless of target words) then\n",
        "    # that's n points.\n",
        "    score += len(correct) - len(incorrect)\n",
        "    \n",
        "    #print('  hint: ', hint_list[n])\n",
        "    #print('  guess: ', g)\n",
        "    #print('correct: ', correct)\n",
        "\n",
        "  if total_possible > 0:\n",
        "    print('total score: ', score, ' ', (score/total_possible))\n",
        "  else:\n",
        "    print('could not generate any hints!')\n",
        "  # print(json.dumps(board, indent=2))\n",
        "\n",
        "  # print(json.dumps(blue_hints, indent=2))\n",
        "  # print(json.dumps(red_hints, indent=2))\n",
        "\n",
        "for s in range(100):\n",
        "  print(\"seed: \", s)\n",
        "  evaluate_wordnet(s)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "seed:  0\n",
            "3  hints\n",
            "total score:  2   0.6666666666666666\n",
            "seed:  1\n",
            "0  hints\n",
            "could not generate any hints!\n",
            "seed:  2\n",
            "5  hints\n",
            "total score:  1   0.2\n",
            "seed:  3\n",
            "0  hints\n",
            "could not generate any hints!\n",
            "seed:  4\n",
            "1  hints\n",
            "total score:  0   0.0\n",
            "seed:  5\n",
            "4  hints\n",
            "total score:  1   0.25\n",
            "seed:  6\n",
            "5  hints\n",
            "total score:  0   0.0\n",
            "seed:  7\n",
            "2  hints\n",
            "total score:  2   1.0\n",
            "seed:  8\n",
            "1  hints\n",
            "total score:  0   0.0\n",
            "seed:  9\n",
            "5  hints\n",
            "total score:  1   0.2\n",
            "seed:  10\n",
            "6  hints\n",
            "total score:  2   0.3333333333333333\n",
            "seed:  11\n",
            "1  hints\n",
            "total score:  0   0.0\n",
            "seed:  12\n",
            "0  hints\n",
            "could not generate any hints!\n",
            "seed:  13\n",
            "0  hints\n",
            "could not generate any hints!\n",
            "seed:  14\n",
            "3  hints\n",
            "total score:  1   0.3333333333333333\n",
            "seed:  15\n",
            "2  hints\n",
            "total score:  1   0.5\n",
            "seed:  16\n",
            "0  hints\n",
            "could not generate any hints!\n",
            "seed:  17\n",
            "0  hints\n",
            "could not generate any hints!\n",
            "seed:  18\n",
            "1  hints\n",
            "total score:  1   1.0\n",
            "seed:  19\n",
            "0  hints\n",
            "could not generate any hints!\n",
            "seed:  20\n",
            "3  hints\n",
            "total score:  0   0.0\n",
            "seed:  21\n",
            "4  hints\n",
            "total score:  1   0.25\n",
            "seed:  22\n",
            "3  hints\n",
            "total score:  1   0.3333333333333333\n",
            "seed:  23\n",
            "5  hints\n",
            "total score:  2   0.4\n",
            "seed:  24\n",
            "3  hints\n",
            "total score:  2   0.6666666666666666\n",
            "seed:  25\n",
            "2  hints\n",
            "total score:  0   0.0\n",
            "seed:  26\n",
            "0  hints\n",
            "could not generate any hints!\n",
            "seed:  27\n",
            "4  hints\n",
            "total score:  1   0.25\n",
            "seed:  28\n",
            "0  hints\n",
            "could not generate any hints!\n",
            "seed:  29\n",
            "1  hints\n",
            "total score:  0   0.0\n",
            "seed:  30\n",
            "0  hints\n",
            "could not generate any hints!\n",
            "seed:  31\n",
            "1  hints\n",
            "total score:  0   0.0\n",
            "seed:  32\n",
            "2  hints\n",
            "total score:  1   0.5\n",
            "seed:  33\n",
            "0  hints\n",
            "could not generate any hints!\n",
            "seed:  34\n",
            "0  hints\n",
            "could not generate any hints!\n",
            "seed:  35\n",
            "1  hints\n",
            "total score:  0   0.0\n",
            "seed:  36\n",
            "3  hints\n",
            "total score:  2   0.6666666666666666\n",
            "seed:  37\n",
            "1  hints\n",
            "total score:  1   1.0\n",
            "seed:  38\n",
            "5  hints\n",
            "total score:  0   0.0\n",
            "seed:  39\n",
            "0  hints\n",
            "could not generate any hints!\n",
            "seed:  40\n",
            "1  hints\n",
            "total score:  1   1.0\n",
            "seed:  41\n",
            "5  hints\n",
            "total score:  0   0.0\n",
            "seed:  42\n",
            "0  hints\n",
            "could not generate any hints!\n",
            "seed:  43\n",
            "2  hints\n",
            "total score:  0   0.0\n",
            "seed:  44\n",
            "1  hints\n",
            "total score:  0   0.0\n",
            "seed:  45\n",
            "0  hints\n",
            "could not generate any hints!\n",
            "seed:  46\n",
            "1  hints\n",
            "total score:  1   1.0\n",
            "seed:  47\n",
            "0  hints\n",
            "could not generate any hints!\n",
            "seed:  48\n",
            "1  hints\n",
            "total score:  1   1.0\n",
            "seed:  49\n",
            "2  hints\n",
            "total score:  1   0.5\n",
            "seed:  50\n",
            "0  hints\n",
            "could not generate any hints!\n",
            "seed:  51\n",
            "2  hints\n",
            "total score:  1   0.5\n",
            "seed:  52\n",
            "1  hints\n",
            "total score:  1   1.0\n",
            "seed:  53\n",
            "0  hints\n",
            "could not generate any hints!\n",
            "seed:  54\n",
            "1  hints\n",
            "total score:  0   0.0\n",
            "seed:  55\n",
            "3  hints\n",
            "total score:  1   0.3333333333333333\n",
            "seed:  56\n",
            "3  hints\n",
            "total score:  1   0.3333333333333333\n",
            "seed:  57\n",
            "0  hints\n",
            "could not generate any hints!\n",
            "seed:  58\n",
            "1  hints\n",
            "total score:  1   1.0\n",
            "seed:  59\n",
            "1  hints\n",
            "total score:  0   0.0\n",
            "seed:  60\n",
            "2  hints\n",
            "total score:  0   0.0\n",
            "seed:  61\n",
            "1  hints\n",
            "total score:  1   1.0\n",
            "seed:  62\n",
            "1  hints\n",
            "total score:  0   0.0\n",
            "seed:  63\n",
            "0  hints\n",
            "could not generate any hints!\n",
            "seed:  64\n",
            "1  hints\n",
            "total score:  1   1.0\n",
            "seed:  65\n",
            "0  hints\n",
            "could not generate any hints!\n",
            "seed:  66\n",
            "4  hints\n",
            "total score:  2   0.5\n",
            "seed:  67\n",
            "4  hints\n",
            "total score:  0   0.0\n",
            "seed:  68\n",
            "4  hints\n",
            "total score:  2   0.5\n",
            "seed:  69\n",
            "2  hints\n",
            "total score:  1   0.5\n",
            "seed:  70\n",
            "1  hints\n",
            "total score:  1   1.0\n",
            "seed:  71\n",
            "4  hints\n",
            "total score:  1   0.25\n",
            "seed:  72\n",
            "3  hints\n",
            "total score:  3   1.0\n",
            "seed:  73\n",
            "2  hints\n",
            "total score:  1   0.5\n",
            "seed:  74\n",
            "0  hints\n",
            "could not generate any hints!\n",
            "seed:  75\n",
            "2  hints\n",
            "total score:  1   0.5\n",
            "seed:  76\n",
            "1  hints\n",
            "total score:  1   1.0\n",
            "seed:  77\n",
            "1  hints\n",
            "total score:  0   0.0\n",
            "seed:  78\n",
            "1  hints\n",
            "total score:  0   0.0\n",
            "seed:  79\n",
            "0  hints\n",
            "could not generate any hints!\n",
            "seed:  80\n",
            "1  hints\n",
            "total score:  1   1.0\n",
            "seed:  81\n",
            "4  hints\n",
            "total score:  1   0.25\n",
            "seed:  82\n",
            "1  hints\n",
            "total score:  0   0.0\n",
            "seed:  83\n",
            "1  hints\n",
            "total score:  1   1.0\n",
            "seed:  84\n",
            "3  hints\n",
            "total score:  1   0.3333333333333333\n",
            "seed:  85\n",
            "0  hints\n",
            "could not generate any hints!\n",
            "seed:  86\n",
            "0  hints\n",
            "could not generate any hints!\n",
            "seed:  87\n",
            "0  hints\n",
            "could not generate any hints!\n",
            "seed:  88\n",
            "0  hints\n",
            "could not generate any hints!\n",
            "seed:  89\n",
            "1  hints\n",
            "total score:  1   1.0\n",
            "seed:  90\n",
            "3  hints\n",
            "total score:  1   0.3333333333333333\n",
            "seed:  91\n",
            "1  hints\n",
            "total score:  0   0.0\n",
            "seed:  92\n",
            "1  hints\n",
            "total score:  1   1.0\n",
            "seed:  93\n",
            "2  hints\n",
            "total score:  2   1.0\n",
            "seed:  94\n",
            "4  hints\n",
            "total score:  1   0.25\n",
            "seed:  95\n",
            "1  hints\n",
            "total score:  0   0.0\n",
            "seed:  96\n",
            "1  hints\n",
            "total score:  0   0.0\n",
            "seed:  97\n",
            "0  hints\n",
            "could not generate any hints!\n",
            "seed:  98\n",
            "3  hints\n",
            "total score:  1   0.3333333333333333\n",
            "seed:  99\n",
            "1  hints\n",
            "total score:  0   0.0\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}